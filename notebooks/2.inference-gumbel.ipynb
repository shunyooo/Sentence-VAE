{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from model_gumbel import SentenceVAE\n",
    "from utils import to_var, idx2word, interpolate, AttributeDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_colwidth\", 500) # 1セルに500文字入る\n",
    "pd.set_option(\"display.max_rows\", 100) # 100行表示できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "#     'cvae_bowloss': './bin/2019-Dec-01-08:47:43/E9.pytorch',\n",
    "#     'cvae_latent200': './bin/2019-Dec-01-10:27:08/E9.pytorch',\n",
    "#     'cvae_bowloss_latent200': './bin/2019-Dec-01-10:25:05/E9.pytorch',\n",
    "#     'cvae_bowloss_latent200_epoch100': './bin/2019-Dec-02-11:02:29/E99.pytorch',\n",
    "#     'vae': './bin/2019-Dec-03-05:31:25/E9.pytorch',\n",
    "#     'vae_gumbel_latent200_tau0.1_epoch100': './bin/2019-Dec-03-12:12:33/E99.pytorch',\n",
    "    'vae_gumbel_latent16_tau0.1_epoch20': './bin/2019-Dec-05-10:01:18/E19.pytorch',\n",
    "    'vae_gumbel_latent200_tau0.1_epoch20': './bin/2019-Dec-05-10:01:32/E19.pytorch',\n",
    "    'vae_gumbel_latent16_tau0.5_epoch20': './bin/2019-Dec-05-10:01:34/E19.pytorch',\n",
    "    'vae_gumbel_latent16_tau1_epoch20': './bin/2019-Dec-05-10:19:22/E19.pytorch',\n",
    "    'vae_gumbel_latent16_tau5_epoch20': './bin/2019-Dec-05-10:20:10/E19.pytorch',\n",
    "    'vae_gumbel_latent16_tau30_epoch20': './bin/2019-Dec-05-17:48:20/E19.pytorch',\n",
    "}\n",
    "tau_dict = {\n",
    "#     'vae_gumbel_latent200_tau0.1_epoch100': 0.1,\n",
    "    'vae_gumbel_latent16_tau0.1_epoch20': 0.1,\n",
    "    'vae_gumbel_latent200_tau0.1_epoch20': 0.1,\n",
    "    'vae_gumbel_latent16_tau0.5_epoch20': 0.5,\n",
    "    'vae_gumbel_latent16_tau1_epoch20': 1,\n",
    "    'vae_gumbel_latent16_tau5_epoch20': 5,\n",
    "    'vae_gumbel_latent16_tau30_epoch20': 30,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'num_samples': 10,\n",
    "    'max_sequence_length': 50,\n",
    "    'embedding_size': 300,\n",
    "    'rnn_type': 'gru',\n",
    "    'hidden_size': 256,\n",
    "    'word_dropout': 0,\n",
    "    'embedding_dropout': 0.5,\n",
    "    'num_layers': 1,\n",
    "    'bidirectional': False\n",
    "}\n",
    "args = AttributeDict(args)\n",
    "args.rnn_type = args.rnn_type.lower()\n",
    "assert args.rnn_type in ['rnn', 'lstm', 'gru']\n",
    "assert 0 <= args.word_dropout <= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(arr_like, cuda=True):\n",
    "    tensor = torch.Tensor(arr_like)\n",
    "    return tensor if not cuda else tensor.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/eccos/src/ptb.vocab.json', 'r') as file:\n",
    "        src_vocab = json.load(file)\n",
    "src_w2i, src_i2w = src_vocab['w2i'], src_vocab['i2w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/eccos/tgt/ptb.vocab.json', 'r') as file:\n",
    "        tgt_vocab = json.load(file)\n",
    "tgt_w2i, tgt_i2w = tgt_vocab['w2i'], tgt_vocab['i2w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5619, 12106)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(src_w2i), len(tgt_w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.obj['cond_embedding_size'] = 300\n",
    "# args.obj['cond_hidden_size'] = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptb import SOS_INDEX, EOS_INDEX, PAD_INDEX, UNK_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _dict = torch.load(model_dict['vae_gumbel'])\n",
    "# model_shapes = {k: v.shape for k,v in _dict.items()}\n",
    "# model_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(name):\n",
    "    path = model_dict[name]\n",
    "    _dict = torch.load(path)\n",
    "    model_shapes = {k: v.shape for k,v in _dict.items()}\n",
    "    ext_kwargs = {}\n",
    "    \n",
    "    # BOW Loss\n",
    "    bow_hidden_shape = model_shapes.get('latent2bow.0.weight')\n",
    "    use_bow_loss = bow_hidden_shape is not None\n",
    "    print(f'BOW Loss: {use_bow_loss}')\n",
    "    if use_bow_loss:\n",
    "        ext_kwargs['bow_hidden_size'] = bow_hidden_shape[0]\n",
    "    else:\n",
    "        ext_kwargs['use_bow_loss'] = False\n",
    "        \n",
    "    # Latent size\n",
    "    latent_size = model_shapes.get('hidden2logv.bias')[0]\n",
    "    print(f'Latent size: {latent_size}')\n",
    "    \n",
    "    # Gumbel\n",
    "    gumbel_vocab_size, gumbel_embedding_size = model_shapes.get('hidden2gumbel.weight', [None, None])\n",
    "    is_gumbel = gumbel_vocab_size is not None\n",
    "    print(f'Gumbel: {is_gumbel}')\n",
    "    if is_gumbel:\n",
    "        ext_kwargs['is_gumbel'] = is_gumbel\n",
    "        ext_kwargs['gumbel_tau'] = tau_dict[name]\n",
    "    print(ext_kwargs)\n",
    "        \n",
    "    model = SentenceVAE(\n",
    "        vocab_size=len(tgt_w2i),\n",
    "        sos_idx=SOS_INDEX,\n",
    "        eos_idx=EOS_INDEX,\n",
    "        pad_idx=PAD_INDEX,\n",
    "        unk_idx=UNK_INDEX,\n",
    "        max_sequence_length=args.max_sequence_length,\n",
    "        embedding_size=args.embedding_size,\n",
    "        rnn_type=args.rnn_type,\n",
    "        hidden_size=args.hidden_size,\n",
    "        word_dropout=args.word_dropout,\n",
    "        embedding_dropout=args.embedding_dropout,\n",
    "        latent_size=latent_size,\n",
    "        num_layers=args.num_layers,\n",
    "        bidirectional=args.bidirectional,        \n",
    "        **ext_kwargs,\n",
    "    )\n",
    "    print(model)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(path)\n",
    "\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    print(\"Model loaded from %s\"%(path))\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        \n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW Loss: False\n",
      "Latent size: 16\n",
      "Gumbel: True\n",
      "{'use_bow_loss': False, 'is_gumbel': True, 'gumbel_tau': 1}\n",
      "SentenceVAE(\n",
      "  (embedding): Embedding(12106, 300)\n",
      "  (decoder_embedding): Embedding(12106, 300)\n",
      "  (embedding_dropout): Dropout(p=0.5, inplace=False)\n",
      "  (encoder_rnn): GRU(300, 256, batch_first=True)\n",
      "  (decoder_rnn): GRU(300, 256, batch_first=True)\n",
      "  (hidden2gumbel): Linear(in_features=256, out_features=12106, bias=True)\n",
      "  (hidden2mean): Linear(in_features=300, out_features=16, bias=True)\n",
      "  (hidden2logv): Linear(in_features=300, out_features=16, bias=True)\n",
      "  (latent2hidden): Linear(in_features=16, out_features=256, bias=True)\n",
      "  (outputs2vocab): Linear(in_features=256, out_features=12106, bias=True)\n",
      ")\n",
      "Model loaded from ./bin/2019-Dec-05-10:19:22/E19.pytorch\n"
     ]
    }
   ],
   "source": [
    "model = load_model('vae_gumbel_latent16_tau1_epoch20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample 指定 inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptb import PTB\n",
    "test_tgt_ptb = PTB(\n",
    "    data_dir='./data/eccos/tgt/',\n",
    "    split='test',\n",
    "    create_data=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実際のデータ確認用\n",
    "def ids2text(id_list, ptb, sep=''):\n",
    "    return sep.join([ptb.i2w[f'{i}'] for i in id_list])\n",
    "\n",
    "def ids2ptext(*args, **kwags):\n",
    "    text = ids2text(*args, **kwags)\n",
    "    return text.replace('<eos>', '').replace('<pad>', '').replace('<sos>', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2ids(words, ptb):\n",
    "    assert type(words) == list\n",
    "    return [ptb.w2i.get(word, UNK_INDEX) for word in words]\n",
    "\n",
    "def words2sample(words, ptb):\n",
    "    id_list = [SOS_INDEX] + words2ids(words, ptb)\n",
    "    sample = {'input': id_list, 'length': len(id_list)}\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(index):\n",
    "    sample = test_tgt_ptb.data[f'{index}']\n",
    "    sample_input = to_tensor(sample['input']).view(1,-1).to(dtype=torch.int64)\n",
    "    sample_length = to_tensor([sample['length']]).to(dtype=torch.int64)\n",
    "    return sample_input, sample_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▼ Input length:tensor([36], device='cuda:0')\n",
      "すっぴんが可愛い子の共通<unk>として、スタイルも綺麗。メイクに頼らずに素から美人になるためにもダイエットを始めてみませんか?\n"
     ]
    }
   ],
   "source": [
    "# データをピックアップ, 確認\n",
    "# sample = words2sample('発想 日焼け止め スキンケア'.split(), test_tgt_ptb)\n",
    "sample_input, sample_length = sample_data(242)\n",
    "print(f'▼ Input length:{sample_length}\\n{ids2ptext(sample_input[0], test_tgt_ptb)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(model, sample_input, sample_length):\n",
    "    # gumbel softmax\n",
    "    with torch.no_grad():\n",
    "        hidden = model.encode(sample_input, sample_length)\n",
    "        gumbel_softmax = model.gumbel_softmax(hidden)\n",
    "        hidden = torch.matmul(gumbel_softmax, model.embedding.weight)\n",
    "        mean, logv, z = model.hidden2latent(hidden)\n",
    "    return {\n",
    "        'hidden': hidden,\n",
    "        'gumbel_softmax': gumbel_softmax,\n",
    "        'mean': mean,\n",
    "        'logv': logv,\n",
    "        'z': z,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _softmax = np.array(softmax.tolist())[0]\n",
    "is_valid = _softmax > 1/len(test_tgt_ptb.i2w)\n",
    "valid_softmax = _softmax[is_valid]\n",
    "sort_index = valid_softmax.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(_softmax > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 901, 2328, 4030, ..., 8066, 8065,    0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_softmax[is_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([901]),)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(is_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.260366760284156e-05"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/len(test_tgt_ptb.i2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_valid = _softmax > 1/len(test_tgt_ptb.i2w)\n",
    "sort_valid_index = _softmax.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3314, 11606])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_valid_index[:is_valid.sum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_index(softmax, threshold):\n",
    "    global _softmax, is_valid\n",
    "    _softmax = np.array(softmax.tolist())[0]\n",
    "    is_valid = _softmax > threshold\n",
    "    sort_valid_index = _softmax.argsort()[::-1][:is_valid.sum()]\n",
    "#     valid_softmax = _softmax[is_valid]\n",
    "#     gs = [{'p': p, 'index': i} for p, i in zip(_softmax[is_valid], np.where(is_valid))]\n",
    "    return list(_softmax[sort_valid_index]), list(sort_valid_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_print_samples(model, sample_input, sample_length, n=30):\n",
    "    # n回サンプリング\n",
    "    args.num_samples = n\n",
    "    encoded = encode(model, sample_input, sample_length)\n",
    "    mean, std = encoded['mean'].squeeze(), torch.exp(0.5 * encoded['logv']).squeeze()\n",
    "    z_dist = torch.distributions.normal.Normal(mean, std)\n",
    "    z_list = z_dist.sample((n, ))\n",
    "    \n",
    "    global gumbel_index_list\n",
    "    gumbel_p_list, gumbel_index_list = softmax_index(encoded['gumbel_softmax'], 1/len(test_tgt_ptb.i2w))\n",
    "    samples, _ = model.inference(z=z_list)\n",
    "    print('■ 入力')\n",
    "    print(ids2ptext(sample_input.squeeze(), test_tgt_ptb))\n",
    "    print('■ 抽出単語')\n",
    "    print(ids2ptext(gumbel_index_list, test_tgt_ptb, sep=' '))\n",
    "    print(f'■ {args.num_samples}件 サンプリング')\n",
    "    print(*[s.replace('<eos>', '').replace(' ', '') for s in idx2word(samples, i2w=tgt_i2w, pad_idx=PAD_INDEX)], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "sample_index_list = random.sample(range(0, len(test_tgt_ptb)), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_test_data(model, index_list):\n",
    "    with torch.no_grad():\n",
    "        encoded_list = []\n",
    "        for i, data_i in enumerate(index_list):\n",
    "            print(f'\\r{i}/{len(index_list)}', end='')\n",
    "            sample_input, sample_length = sample_data(data_i)\n",
    "            encoded = encode(model, sample_input, sample_length)\n",
    "\n",
    "            decoded_ids, _ = model.inference(z=encoded['mean'])\n",
    "\n",
    "            input_text = ids2ptext(sample_input.squeeze(), test_tgt_ptb)\n",
    "\n",
    "            # 単語抽出\n",
    "            gumbel_p_list, gumbel_index_list = softmax_index(encoded['gumbel_softmax'], 1/len(test_tgt_ptb))\n",
    "            gumbel_kws = [test_tgt_ptb.i2w[f'{i}'] for i in gumbel_index_list]\n",
    "            decoded_text = ids2ptext(decoded_ids.squeeze(), test_tgt_ptb)\n",
    "\n",
    "            encoded_list.append({\n",
    "                'input_text': input_text,\n",
    "                'gumbel_kws': gumbel_kws,\n",
    "                'gumbel_probs': gumbel_p_list,\n",
    "                'decoded_text': decoded_text,\n",
    "                # **encoded,\n",
    "            })\n",
    "        return encoded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vae_gumbel_latent16_tau0.1_epoch20\n",
      "BOW Loss: False\n",
      "Latent size: 16\n",
      "Gumbel: True\n",
      "{'use_bow_loss': False, 'is_gumbel': True, 'gumbel_tau': 0.1}\n",
      "SentenceVAE(\n",
      "  (embedding): Embedding(12106, 300)\n",
      "  (decoder_embedding): Embedding(12106, 300)\n",
      "  (embedding_dropout): Dropout(p=0.5, inplace=False)\n",
      "  (encoder_rnn): GRU(300, 256, batch_first=True)\n",
      "  (decoder_rnn): GRU(300, 256, batch_first=True)\n",
      "  (hidden2gumbel): Linear(in_features=256, out_features=12106, bias=True)\n",
      "  (hidden2mean): Linear(in_features=300, out_features=16, bias=True)\n",
      "  (hidden2logv): Linear(in_features=300, out_features=16, bias=True)\n",
      "  (latent2hidden): Linear(in_features=16, out_features=256, bias=True)\n",
      "  (outputs2vocab): Linear(in_features=256, out_features=12106, bias=True)\n",
      ")\n",
      "Model loaded from ./bin/2019-Dec-05-10:01:18/E19.pytorch\n",
      "999/1000vae_gumbel_latent16_tau0.5_epoch20\n",
      "BOW Loss: False\n",
      "Latent size: 16\n",
      "Gumbel: True\n",
      "{'use_bow_loss': False, 'is_gumbel': True, 'gumbel_tau': 0.5}\n",
      "SentenceVAE(\n",
      "  (embedding): Embedding(12106, 300)\n",
      "  (decoder_embedding): Embedding(12106, 300)\n",
      "  (embedding_dropout): Dropout(p=0.5, inplace=False)\n",
      "  (encoder_rnn): GRU(300, 256, batch_first=True)\n",
      "  (decoder_rnn): GRU(300, 256, batch_first=True)\n",
      "  (hidden2gumbel): Linear(in_features=256, out_features=12106, bias=True)\n",
      "  (hidden2mean): Linear(in_features=300, out_features=16, bias=True)\n",
      "  (hidden2logv): Linear(in_features=300, out_features=16, bias=True)\n",
      "  (latent2hidden): Linear(in_features=16, out_features=256, bias=True)\n",
      "  (outputs2vocab): Linear(in_features=256, out_features=12106, bias=True)\n",
      ")\n",
      "Model loaded from ./bin/2019-Dec-05-10:01:34/E19.pytorch\n",
      "999/1000vae_gumbel_latent16_tau1_epoch20\n",
      "BOW Loss: False\n",
      "Latent size: 16\n",
      "Gumbel: True\n",
      "{'use_bow_loss': False, 'is_gumbel': True, 'gumbel_tau': 1}\n",
      "SentenceVAE(\n",
      "  (embedding): Embedding(12106, 300)\n",
      "  (decoder_embedding): Embedding(12106, 300)\n",
      "  (embedding_dropout): Dropout(p=0.5, inplace=False)\n",
      "  (encoder_rnn): GRU(300, 256, batch_first=True)\n",
      "  (decoder_rnn): GRU(300, 256, batch_first=True)\n",
      "  (hidden2gumbel): Linear(in_features=256, out_features=12106, bias=True)\n",
      "  (hidden2mean): Linear(in_features=300, out_features=16, bias=True)\n",
      "  (hidden2logv): Linear(in_features=300, out_features=16, bias=True)\n",
      "  (latent2hidden): Linear(in_features=16, out_features=256, bias=True)\n",
      "  (outputs2vocab): Linear(in_features=256, out_features=12106, bias=True)\n",
      ")\n",
      "Model loaded from ./bin/2019-Dec-05-10:19:22/E19.pytorch\n",
      "999/1000vae_gumbel_latent16_tau5_epoch20\n",
      "BOW Loss: False\n",
      "Latent size: 16\n",
      "Gumbel: True\n",
      "{'use_bow_loss': False, 'is_gumbel': True, 'gumbel_tau': 5}\n",
      "SentenceVAE(\n",
      "  (embedding): Embedding(12106, 300)\n",
      "  (decoder_embedding): Embedding(12106, 300)\n",
      "  (embedding_dropout): Dropout(p=0.5, inplace=False)\n",
      "  (encoder_rnn): GRU(300, 256, batch_first=True)\n",
      "  (decoder_rnn): GRU(300, 256, batch_first=True)\n",
      "  (hidden2gumbel): Linear(in_features=256, out_features=12106, bias=True)\n",
      "  (hidden2mean): Linear(in_features=300, out_features=16, bias=True)\n",
      "  (hidden2logv): Linear(in_features=300, out_features=16, bias=True)\n",
      "  (latent2hidden): Linear(in_features=16, out_features=256, bias=True)\n",
      "  (outputs2vocab): Linear(in_features=256, out_features=12106, bias=True)\n",
      ")\n",
      "Model loaded from ./bin/2019-Dec-05-10:20:10/E19.pytorch\n",
      "999/1000vae_gumbel_latent16_tau30_epoch20\n",
      "BOW Loss: False\n",
      "Latent size: 16\n",
      "Gumbel: True\n",
      "{'use_bow_loss': False, 'is_gumbel': True, 'gumbel_tau': 30}\n",
      "SentenceVAE(\n",
      "  (embedding): Embedding(12106, 300)\n",
      "  (decoder_embedding): Embedding(12106, 300)\n",
      "  (embedding_dropout): Dropout(p=0.5, inplace=False)\n",
      "  (encoder_rnn): GRU(300, 256, batch_first=True)\n",
      "  (decoder_rnn): GRU(300, 256, batch_first=True)\n",
      "  (hidden2gumbel): Linear(in_features=256, out_features=12106, bias=True)\n",
      "  (hidden2mean): Linear(in_features=300, out_features=16, bias=True)\n",
      "  (hidden2logv): Linear(in_features=300, out_features=16, bias=True)\n",
      "  (latent2hidden): Linear(in_features=16, out_features=256, bias=True)\n",
      "  (outputs2vocab): Linear(in_features=256, out_features=12106, bias=True)\n",
      ")\n",
      "Model loaded from ./bin/2019-Dec-05-17:48:20/E19.pytorch\n",
      "999/1000CPU times: user 2min 40s, sys: 9.08 s, total: 2min 49s\n",
      "Wall time: 2min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def load_and_encode(name):\n",
    "    print(name)\n",
    "    model = load_model(name)\n",
    "    encoded_list = encode_test_data(model, sample_index_list)\n",
    "    return encoded_list\n",
    "    \n",
    "model_test_encoded = {name: load_and_encode(name) for name in model_dict.keys() if 'latent16' in name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_test_encoded['vae_gumbel_latent16_tau0.1_epoch20'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model_test_encoded['vae_gumbel_latent16_tau0.1_epoch20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = []\n",
    "for name, e in model_test_encoded.items():\n",
    "    df = pd.DataFrame(e)\n",
    "    df['name'] = name\n",
    "    df_data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_data = pd.concat(df_data)\n",
    "df_all_data['kw_num'] = df_all_data.gumbel_kws.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_all_data[['name', 'input_text', 'gumbel_kws', 'gumbel_probs', 'kw_num', 'decoded_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>input_text</th>\n",
       "      <th>gumbel_kws</th>\n",
       "      <th>gumbel_probs</th>\n",
       "      <th>kw_num</th>\n",
       "      <th>decoded_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>vae_gumbel_latent16_tau30_epoch20</td>\n",
       "      <td>冬こそダメージケア!&lt;person&gt;髪になれるヘアケアアイテム</td>\n",
       "      <td>[メガホン, 乾かす, エキス, パック, ドキッ, 勝負服, 変えれ, ラボ, 靴擦れ, 愛らしい, 締まっ, あなた色, アイケア, あれ, ヶ所, 温, 言い, 落とせる, バングス, 早期, チェック, 近道, 品切れ, 圧倒的, すっ, ので, 白肌, 柔らかい肌, 入れる, 左右, ヶ月, しょう, 年度, モテ仕草, きれい, 実施, 確かめ, カシミヤ, 創業, 既に, 意外, 雨, 今晩, 破産法, れる, クリスマスプレゼント, アディクション, 未知, サポート, セミロング, ≪, 陶器, 年間, 境界線, ω, アイメイク, 宝庫, アボカド, 診断, 色素, 噂, ツヤ感, 一部, しまっ, サービス, 探し, 努力, 結果, つらーい, スイーツレシピ, 追加, ほど, うんざり, なかっ, 果物, jk, クオリティ, 暑かっ, 一生, 体, お家, ピッタリ, 眠い, 知っ, だけ, まゆ毛, 竹下通り, 経験, 黒, ガール, 上げ, 慣れ, 会, がっかり, ニット, 飯, 合っ, リキッドルージュ, なんか, コラボ, ...]</td>\n",
       "      <td>[0.0032996749505400658, 0.0030826895963400602, 0.0026851564180105925, 0.0026479666121304035, 0.0009239482460543513, 0.000915618147701025, 0.0008479719399474561, 0.0007803154294379056, 0.0007802715408615768, 0.0007713402155786753, 0.0007645838195458055, 0.0007389404345303774, 0.0007341925520449877, 0.0007017346215434372, 0.0006770046311430633, 0.0006366467569023371, 0.0006162656936794519, 0.0006115199066698551, 0.0005706542287953198, 0.0005610229563899338, 0.0005530543276108801, 0.00052332889...</td>\n",
       "      <td>3064</td>\n",
       "      <td>&lt;person&gt;の新作コスメがかわいすぎる!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name                       input_text  \\\n",
       "653  vae_gumbel_latent16_tau30_epoch20  冬こそダメージケア!<person>髪になれるヘアケアアイテム   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      gumbel_kws  \\\n",
       "653  [メガホン, 乾かす, エキス, パック, ドキッ, 勝負服, 変えれ, ラボ, 靴擦れ, 愛らしい, 締まっ, あなた色, アイケア, あれ, ヶ所, 温, 言い, 落とせる, バングス, 早期, チェック, 近道, 品切れ, 圧倒的, すっ, ので, 白肌, 柔らかい肌, 入れる, 左右, ヶ月, しょう, 年度, モテ仕草, きれい, 実施, 確かめ, カシミヤ, 創業, 既に, 意外, 雨, 今晩, 破産法, れる, クリスマスプレゼント, アディクション, 未知, サポート, セミロング, ≪, 陶器, 年間, 境界線, ω, アイメイク, 宝庫, アボカド, 診断, 色素, 噂, ツヤ感, 一部, しまっ, サービス, 探し, 努力, 結果, つらーい, スイーツレシピ, 追加, ほど, うんざり, なかっ, 果物, jk, クオリティ, 暑かっ, 一生, 体, お家, ピッタリ, 眠い, 知っ, だけ, まゆ毛, 竹下通り, 経験, 黒, ガール, 上げ, 慣れ, 会, がっかり, ニット, 飯, 合っ, リキッドルージュ, なんか, コラボ, ...]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            gumbel_probs  \\\n",
       "653  [0.0032996749505400658, 0.0030826895963400602, 0.0026851564180105925, 0.0026479666121304035, 0.0009239482460543513, 0.000915618147701025, 0.0008479719399474561, 0.0007803154294379056, 0.0007802715408615768, 0.0007713402155786753, 0.0007645838195458055, 0.0007389404345303774, 0.0007341925520449877, 0.0007017346215434372, 0.0006770046311430633, 0.0006366467569023371, 0.0006162656936794519, 0.0006115199066698551, 0.0005706542287953198, 0.0005610229563899338, 0.0005530543276108801, 0.00052332889...   \n",
       "\n",
       "     kw_num            decoded_text  \n",
       "653    3064  <person>の新作コスメがかわいすぎる!  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>input_text</th>\n",
       "      <th>gumbel_kws</th>\n",
       "      <th>gumbel_probs</th>\n",
       "      <th>kw_num</th>\n",
       "      <th>decoded_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>vae_gumbel_latent16_tau0.1_epoch20</td>\n",
       "      <td>冬こそダメージケア!&lt;person&gt;髪になれるヘアケアアイテム</td>\n",
       "      <td>[デイクリーム]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>【&lt;num&gt;年最新版】&lt;num&gt;月号の雑誌付録が豪華すぎる!&lt;num&gt;月号雑誌付録がどれも豪華すぎる!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>vae_gumbel_latent16_tau0.5_epoch20</td>\n",
       "      <td>冬こそダメージケア!&lt;person&gt;髪になれるヘアケアアイテム</td>\n",
       "      <td>[ベストコスメランキング, させる, 体重計]</td>\n",
       "      <td>[0.8605139851570129, 0.09401451051235199, 0.045468688011169434]</td>\n",
       "      <td>3</td>\n",
       "      <td>【&lt;num&gt;年最新版】人気のbbクリームまとめ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>vae_gumbel_latent16_tau1_epoch20</td>\n",
       "      <td>冬こそダメージケア!&lt;person&gt;髪になれるヘアケアアイテム</td>\n",
       "      <td>[大胆, リプライ, 金額, 見落とし, 可愛く, 豆, 変えよ, 長所, 気, ふさわしい, 背, もらい, リムーバー, 妖精, 休暇, 咲き誇る, 沿線, による, 養蜂, 高さ, エビ, 結婚, レベル, に学ぶ, モチーフコスメ, 定額制, 性, 韓国式, 給料, 比較, お姫様, 太っ, 大き, 徹底的, 光と影, ソックス, きゅうり, スポットライト, 難しいー, 深い, ころん, 浸透, ボディショップ, むら, 神奈川, ポリッシャー, いえ, 手抜き, 再入荷, フラット, 度, ハイクオリティ]</td>\n",
       "      <td>[0.4670945107936859, 0.3388666808605194, 0.03131188824772835, 0.02235434763133526, 0.02213246189057827, 0.019365014508366585, 0.018594296649098396, 0.011130429804325104, 0.01047907117754221, 0.010127858258783817, 0.00926455482840538, 0.006829794961959124, 0.0068010143004357815, 0.004563991446048021, 0.0020591109059751034, 0.001619383692741394, 0.001512541202828288, 0.0012544573983177543, 0.0011133374646306038, 0.0009107079240493476, 0.0007614127243869007, 0.0007026929524727166, 0.00067313225...</td>\n",
       "      <td>52</td>\n",
       "      <td>【&lt;num&gt;年版】人気のリップクリーム&lt;num&gt;選!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>vae_gumbel_latent16_tau5_epoch20</td>\n",
       "      <td>冬こそダメージケア!&lt;person&gt;髪になれるヘアケアアイテム</td>\n",
       "      <td>[夕方, 目尻, ドンキ, 本館, 勢揃い, t, 至極, もちっと, 間に合う, 恒例, アロマ, 控えめ, ぞ, 不動, 忍ばせ, 小売り, 歩む, ジブリ, 勢い, メルヴェイユーズラデュレ, カサカサ, スポーツ, 光る, い, マジ, ‍, パーフェクトワン, おめかし, 困る, 告白, サービス, 新ブランド, という, レブロン, とろり, 密閉, ドモホルンリンクル, 紫外線, ラガーフェルド, サポート, 平行, jj, 赤ちゃん, 使い, 脱い, 利き手, 順, カタログ, 純度, gw, 南国, ジワジワ, 実力, わたし, 泊まり, サークル, 下半身, もの, みずみずしい, 立体的, コラボ, コロっと, エーザイ, ホール, &lt;person&gt;, ポーチインコスメ, 昼ごはん, 広がり, 色白, 定期購入, 巡っ, ストリート, もち肌, 新感覚, デジタル, なんとか, _, 盛り上がり, シトラス, ビストロ, まくり, 摂り, モノクロ, 仲良く, 内定, サテン, つけ, 楽ちん, たまらない, 年末年始, くずれ, エイジング, なー, も...</td>\n",
       "      <td>[0.005914709530770779, 0.005350309889763594, 0.003935209475457668, 0.003222839208319783, 0.003156389342620969, 0.0028806617483496666, 0.002791693666949868, 0.00248090666718781, 0.0024229073897004128, 0.002398343291133642, 0.0023278705775737762, 0.002292066579684615, 0.002185804070904851, 0.002153356559574604, 0.002149736974388361, 0.0020031158346682787, 0.002002231776714325, 0.0019839939195662737, 0.0019766660407185555, 0.0019562651868909597, 0.001936300890520215, 0.0018561322940513492, 0.00...</td>\n",
       "      <td>2399</td>\n",
       "      <td>お風呂上がりにおすすめ!&lt;unk&gt;で美肌を叶える方法</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>vae_gumbel_latent16_tau30_epoch20</td>\n",
       "      <td>冬こそダメージケア!&lt;person&gt;髪になれるヘアケアアイテム</td>\n",
       "      <td>[メガホン, 乾かす, エキス, パック, ドキッ, 勝負服, 変えれ, ラボ, 靴擦れ, 愛らしい, 締まっ, あなた色, アイケア, あれ, ヶ所, 温, 言い, 落とせる, バングス, 早期, チェック, 近道, 品切れ, 圧倒的, すっ, ので, 白肌, 柔らかい肌, 入れる, 左右, ヶ月, しょう, 年度, モテ仕草, きれい, 実施, 確かめ, カシミヤ, 創業, 既に, 意外, 雨, 今晩, 破産法, れる, クリスマスプレゼント, アディクション, 未知, サポート, セミロング, ≪, 陶器, 年間, 境界線, ω, アイメイク, 宝庫, アボカド, 診断, 色素, 噂, ツヤ感, 一部, しまっ, サービス, 探し, 努力, 結果, つらーい, スイーツレシピ, 追加, ほど, うんざり, なかっ, 果物, jk, クオリティ, 暑かっ, 一生, 体, お家, ピッタリ, 眠い, 知っ, だけ, まゆ毛, 竹下通り, 経験, 黒, ガール, 上げ, 慣れ, 会, がっかり, ニット, 飯, 合っ, リキッドルージュ, なんか, コラボ, ...]</td>\n",
       "      <td>[0.0032996749505400658, 0.0030826895963400602, 0.0026851564180105925, 0.0026479666121304035, 0.0009239482460543513, 0.000915618147701025, 0.0008479719399474561, 0.0007803154294379056, 0.0007802715408615768, 0.0007713402155786753, 0.0007645838195458055, 0.0007389404345303774, 0.0007341925520449877, 0.0007017346215434372, 0.0006770046311430633, 0.0006366467569023371, 0.0006162656936794519, 0.0006115199066698551, 0.0005706542287953198, 0.0005610229563899338, 0.0005530543276108801, 0.00052332889...</td>\n",
       "      <td>3064</td>\n",
       "      <td>&lt;person&gt;の新作コスメがかわいすぎる!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   name                       input_text  \\\n",
       "653  vae_gumbel_latent16_tau0.1_epoch20  冬こそダメージケア!<person>髪になれるヘアケアアイテム   \n",
       "653  vae_gumbel_latent16_tau0.5_epoch20  冬こそダメージケア!<person>髪になれるヘアケアアイテム   \n",
       "653    vae_gumbel_latent16_tau1_epoch20  冬こそダメージケア!<person>髪になれるヘアケアアイテム   \n",
       "653    vae_gumbel_latent16_tau5_epoch20  冬こそダメージケア!<person>髪になれるヘアケアアイテム   \n",
       "653   vae_gumbel_latent16_tau30_epoch20  冬こそダメージケア!<person>髪になれるヘアケアアイテム   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              gumbel_kws  \\\n",
       "653                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [デイクリーム]   \n",
       "653                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [ベストコスメランキング, させる, 体重計]   \n",
       "653                                                                                                                                                                                                                                               [大胆, リプライ, 金額, 見落とし, 可愛く, 豆, 変えよ, 長所, 気, ふさわしい, 背, もらい, リムーバー, 妖精, 休暇, 咲き誇る, 沿線, による, 養蜂, 高さ, エビ, 結婚, レベル, に学ぶ, モチーフコスメ, 定額制, 性, 韓国式, 給料, 比較, お姫様, 太っ, 大き, 徹底的, 光と影, ソックス, きゅうり, スポットライト, 難しいー, 深い, ころん, 浸透, ボディショップ, むら, 神奈川, ポリッシャー, いえ, 手抜き, 再入荷, フラット, 度, ハイクオリティ]   \n",
       "653  [夕方, 目尻, ドンキ, 本館, 勢揃い, t, 至極, もちっと, 間に合う, 恒例, アロマ, 控えめ, ぞ, 不動, 忍ばせ, 小売り, 歩む, ジブリ, 勢い, メルヴェイユーズラデュレ, カサカサ, スポーツ, 光る, い, マジ, ‍, パーフェクトワン, おめかし, 困る, 告白, サービス, 新ブランド, という, レブロン, とろり, 密閉, ドモホルンリンクル, 紫外線, ラガーフェルド, サポート, 平行, jj, 赤ちゃん, 使い, 脱い, 利き手, 順, カタログ, 純度, gw, 南国, ジワジワ, 実力, わたし, 泊まり, サークル, 下半身, もの, みずみずしい, 立体的, コラボ, コロっと, エーザイ, ホール, <person>, ポーチインコスメ, 昼ごはん, 広がり, 色白, 定期購入, 巡っ, ストリート, もち肌, 新感覚, デジタル, なんとか, _, 盛り上がり, シトラス, ビストロ, まくり, 摂り, モノクロ, 仲良く, 内定, サテン, つけ, 楽ちん, たまらない, 年末年始, くずれ, エイジング, なー, も...   \n",
       "653          [メガホン, 乾かす, エキス, パック, ドキッ, 勝負服, 変えれ, ラボ, 靴擦れ, 愛らしい, 締まっ, あなた色, アイケア, あれ, ヶ所, 温, 言い, 落とせる, バングス, 早期, チェック, 近道, 品切れ, 圧倒的, すっ, ので, 白肌, 柔らかい肌, 入れる, 左右, ヶ月, しょう, 年度, モテ仕草, きれい, 実施, 確かめ, カシミヤ, 創業, 既に, 意外, 雨, 今晩, 破産法, れる, クリスマスプレゼント, アディクション, 未知, サポート, セミロング, ≪, 陶器, 年間, 境界線, ω, アイメイク, 宝庫, アボカド, 診断, 色素, 噂, ツヤ感, 一部, しまっ, サービス, 探し, 努力, 結果, つらーい, スイーツレシピ, 追加, ほど, うんざり, なかっ, 果物, jk, クオリティ, 暑かっ, 一生, 体, お家, ピッタリ, 眠い, 知っ, だけ, まゆ毛, 竹下通り, 経験, 黒, ガール, 上げ, 慣れ, 会, がっかり, ニット, 飯, 合っ, リキッドルージュ, なんか, コラボ, ...]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            gumbel_probs  \\\n",
       "653                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [1.0]   \n",
       "653                                                                                                                                                                                                                                                                                                                                                                                                                                                      [0.8605139851570129, 0.09401451051235199, 0.045468688011169434]   \n",
       "653  [0.4670945107936859, 0.3388666808605194, 0.03131188824772835, 0.02235434763133526, 0.02213246189057827, 0.019365014508366585, 0.018594296649098396, 0.011130429804325104, 0.01047907117754221, 0.010127858258783817, 0.00926455482840538, 0.006829794961959124, 0.0068010143004357815, 0.004563991446048021, 0.0020591109059751034, 0.001619383692741394, 0.001512541202828288, 0.0012544573983177543, 0.0011133374646306038, 0.0009107079240493476, 0.0007614127243869007, 0.0007026929524727166, 0.00067313225...   \n",
       "653  [0.005914709530770779, 0.005350309889763594, 0.003935209475457668, 0.003222839208319783, 0.003156389342620969, 0.0028806617483496666, 0.002791693666949868, 0.00248090666718781, 0.0024229073897004128, 0.002398343291133642, 0.0023278705775737762, 0.002292066579684615, 0.002185804070904851, 0.002153356559574604, 0.002149736974388361, 0.0020031158346682787, 0.002002231776714325, 0.0019839939195662737, 0.0019766660407185555, 0.0019562651868909597, 0.001936300890520215, 0.0018561322940513492, 0.00...   \n",
       "653  [0.0032996749505400658, 0.0030826895963400602, 0.0026851564180105925, 0.0026479666121304035, 0.0009239482460543513, 0.000915618147701025, 0.0008479719399474561, 0.0007803154294379056, 0.0007802715408615768, 0.0007713402155786753, 0.0007645838195458055, 0.0007389404345303774, 0.0007341925520449877, 0.0007017346215434372, 0.0006770046311430633, 0.0006366467569023371, 0.0006162656936794519, 0.0006115199066698551, 0.0005706542287953198, 0.0005610229563899338, 0.0005530543276108801, 0.00052332889...   \n",
       "\n",
       "     kw_num                                         decoded_text  \n",
       "653       1  【<num>年最新版】<num>月号の雑誌付録が豪華すぎる!<num>月号雑誌付録がどれも豪華すぎる!  \n",
       "653       3                              【<num>年最新版】人気のbbクリームまとめ  \n",
       "653      52                           【<num>年版】人気のリップクリーム<num>選!  \n",
       "653    2399                           お風呂上がりにおすすめ!<unk>で美肌を叶える方法  \n",
       "653    3064                               <person>の新作コスメがかわいすぎる!  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.input_text=='冬こそダメージケア!<person>髪になれるヘアケアアイテム']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>input_text</th>\n",
       "      <th>gumbel_kws</th>\n",
       "      <th>gumbel_probs</th>\n",
       "      <th>decoded_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, input_text, gumbel_kws, gumbel_probs, decoded_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.input_text=='☆艶肌・ツル肌目指す洗顔料☆']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['vae_gumbel_latent16_tau0.1_epoch20',\n",
       "       'vae_gumbel_latent200_tau0.1_epoch20',\n",
       "       'vae_gumbel_latent16_tau1_epoch20',\n",
       "       'vae_gumbel_latent16_tau5_epoch20'], dtype=object)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_df = df[df.input_text=='ノーファンデ女子急増中!<person>が愛用するコスメはプロの現場で重宝されている実力派!「同世代に自信をもっておすすめしたいスキンケアです!']\n",
    "# m_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytablewriter\n",
    "# writer = pytablewriter.MarkdownTableWriter()\n",
    "# writer.from_dataframe(m_df)\n",
    "# writer.write_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(encoded_list)\n",
    "df['kw_str'] = df.gumbel_kws.apply(lambda x: ' '.join(x))\n",
    "df = df[['input_text', 'gumbel_kws', 'kw_str', 'gumbel_probs', 'decoded_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['input_text', 'gumbel_kws', 'gumbel_probs', 'decoded_text']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install japanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "plt.figure(figsize=(10, 5))\n",
    "kw_count = df.groupby('kw_size').count()\n",
    "# plt.title('横軸：キーワード数, 縦軸：レコード数（テストデータ）')\n",
    "# plt.xticks(kw_count.index)\n",
    "# plt.bar(kw_count.index, kw_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_size</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count\n",
       "kw_size       \n",
       "1         6325\n",
       "2          345\n",
       "3           14\n",
       "4            1"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_count[['count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 4)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_str</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>絵本</th>\n",
       "      <td>925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>鮮やか</th>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>頑張る</th>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>びや</th>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>日本酒</th>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>再販</th>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>考える力</th>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>覚悟</th>\n",
       "      <td>518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>スピルリナ</th>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ハイヒール</th>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>染み</th>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>平成最後</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>覚悟 考える力</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>考える力 びや</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>絵本 びや</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>頑張る 考える力</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>平成最後 頑張る</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>日本酒 びや</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>平成最後 日本酒</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>頑張る 染み</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>頑張る 覚悟</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>頑張る 日本酒</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>頑張る スピルリナ</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>再販 考える力</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>平成最後 ハイヒール</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>日本酒 ハイヒール</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>日本酒 考える力</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>覚悟 再販</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>頑張る 再販</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>頑張る 考える力 びや</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>頑張る びや</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>覚悟 びや</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>鮮やか 再販</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>平成最後 頑張る 染み</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>絵本 鮮やか</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>日本酒 再販</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>日本酒 考える力 びや</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>平成最後 染み</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>平成最後 頑張る スピルリナ</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>頑張る 日本酒 考える力 びや</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>スピルリナ 染み</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>頑張る 覚悟 考える力</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>平成最後 覚悟</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>頑張る 日本酒 びや</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>頑張る 日本酒 考える力</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>平成最後 びや</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>平成最後 日本酒 ハイヒール</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>絵本 日本酒 びや</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ハイヒール 染み</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>考える力 染み</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>覚悟 再販 考える力</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>平成最後 頑張る びや</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count\n",
       "kw_str                \n",
       "絵本                 925\n",
       "鮮やか                695\n",
       "頑張る                608\n",
       "びや                 607\n",
       "日本酒                599\n",
       "再販                 560\n",
       "考える力               523\n",
       "覚悟                 518\n",
       "スピルリナ              481\n",
       "ハイヒール              365\n",
       "染み                 344\n",
       "平成最後               100\n",
       "覚悟 考える力             67\n",
       "考える力 びや             67\n",
       "絵本 びや               37\n",
       "頑張る 考える力            35\n",
       "平成最後 頑張る            32\n",
       "日本酒 びや              17\n",
       "平成最後 日本酒            13\n",
       "頑張る 染み              12\n",
       "頑張る 覚悟              11\n",
       "頑張る 日本酒              8\n",
       "頑張る スピルリナ            7\n",
       "再販 考える力              6\n",
       "平成最後 ハイヒール           5\n",
       "日本酒 ハイヒール            4\n",
       "日本酒 考える力             3\n",
       "覚悟 再販                2\n",
       "頑張る 再販               2\n",
       "頑張る 考える力 びや          2\n",
       "頑張る びや               2\n",
       "覚悟 びや                2\n",
       "鮮やか 再販               2\n",
       "平成最後 頑張る 染み          2\n",
       "絵本 鮮やか               2\n",
       "日本酒 再販               2\n",
       "日本酒 考える力 びや          2\n",
       "平成最後 染み              2\n",
       "平成最後 頑張る スピルリナ       1\n",
       "頑張る 日本酒 考える力 びや      1\n",
       "スピルリナ 染み             1\n",
       "頑張る 覚悟 考える力          1\n",
       "平成最後 覚悟              1\n",
       "頑張る 日本酒 びや           1\n",
       "頑張る 日本酒 考える力         1\n",
       "平成最後 びや              1\n",
       "平成最後 日本酒 ハイヒール       1\n",
       "絵本 日本酒 びや            1\n",
       "ハイヒール 染み             1\n",
       "考える力 染み              1\n",
       "覚悟 再販 考える力           1\n",
       "平成最後 頑張る びや          1"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['count'] = 1\n",
    "kw_count = df.groupby('kw_str').count()\n",
    "kw_count.sort_values('count', ascending=False)[['count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1, 2, 3, 4], dtype='int64', name='kw_size')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('kw_size').count().input_text.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.kw_str == 'スピルリナ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = [e[''] for e in encoded_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_w = [[test_tgt_ptb.i2w[f'{i}'] for i in ids] for ids in gs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_wl = []\n",
    "for e in encoded_list:\n",
    "    gs_wl += e['gumbel_kws']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs_wl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9603"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gs_wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(gs_wl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'はじめよ',\n",
       " 'びや',\n",
       " 'スピルリナ',\n",
       " 'ハイヒール',\n",
       " 'パーカー',\n",
       " '再販',\n",
       " '培養',\n",
       " '平成最後',\n",
       " '日本酒',\n",
       " '染み',\n",
       " '絵本',\n",
       " '考える力',\n",
       " '覚悟',\n",
       " '頑張る',\n",
       " '鮮やか'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(gs_wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input, sample_length = sample_data(37)\n",
    "encode_print_samples(model, sample_input, sample_length, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 潜在空間のプロット\n",
    "圧縮して分布を確認してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 描画用\n",
    "# https://github.com/lmcinnes/umap/blob/master/notebooks/UMAP%20usage%20and%20parameters.ipynb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(style='white', rc={'figure.figsize':(12,8)})\n",
    "def plot_scatter(u, title=''):\n",
    "    fig = plt.figure()\n",
    "    n_components = u.shape[1]\n",
    "    plot_kwargs = {'alpha': 0.5, 's':5}\n",
    "    if n_components == 1:\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.scatter(u[:,0], range(len(u)), **plot_kwargs)\n",
    "    if n_components == 2:\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.scatter(u[:,0], u[:,1], **plot_kwargs)\n",
    "    if n_components == 3:\n",
    "        ax = fig.add_subplot(111, projection='3d', **plot_kwargs)\n",
    "        ax.scatter(u[:,0], u[:,1], u[:,2])\n",
    "    plt.title(title, fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptb import PTB\n",
    "src_test_ptb = PTB(\n",
    "    data_dir='./data/eccos/src/',\n",
    "    split='test',\n",
    "    create_data=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_test_ptb = PTB(\n",
    "    data_dir='./data/eccos/tgt/',\n",
    "    split='test',\n",
    "    create_data=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エンコードする対象を指定する\n",
    "test_ptb = tgt_test_ptb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_to_tensor(sample):\n",
    "    sample_input = to_tensor(sample['input']).view(1,-1).to(dtype=torch.int64)\n",
    "    sample_length = to_tensor([sample['length']]).to(dtype=torch.int64)\n",
    "    return sample_input, sample_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# テストデータを潜在変数に変換\n",
    "with torch.no_grad():\n",
    "    # encoded_samples = [model.encode(*sample_to_tensor(sample)) for i, sample in test_ptb.data.items()]\n",
    "    if model.is_conditional:\n",
    "        print('Encode Condition...')\n",
    "        encoded_samples = [model.encode_condition(*sample_to_tensor(sample)) for i, sample in test_ptb.data.items()]\n",
    "        encoded_mean_list = [cond_mean.tolist() for cond_hidden, cond_mean, cond_logv, cond_z in encoded_samples]\n",
    "    else:\n",
    "        print('Encode...')\n",
    "        encoded_samples = [model.encode(*sample_to_tensor(sample)) for i, sample in test_ptb.data.items()]\n",
    "        encoded_mean_list = [mean.tolist() for mean, logv, z in encoded_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_mean_arr = np.array(encoded_mean_list).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mean_u = umap.UMAP().fit_transform(encoded_mean_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(mean_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard Embedding Projectorへ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "limit = 5000\n",
    "df = pd.DataFrame(test_ptb.data).T\n",
    "test_label_list = [ids2ptext(target, test_ptb) for target in df.target.tolist()]\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "log_dir = '/root/user/work/logs'\n",
    "model_name = f'gumbel_vae_latent16_epoch100_n={limit}'\n",
    "writer = SummaryWriter(f'{log_dir}/{model_name}')\n",
    "writer.add_embedding(torch.FloatTensor(encoded_mean_arr[:limit]), metadata=test_label_list[:limit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_onehot(indexs):\n",
    "    h = torch.zeros(model.embedding.weight.shape[0]).cuda()\n",
    "    h[indexs] = 1\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexs = [0, 1]\n",
    "onehot = make_onehot(indexs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = torch.matmul(h, model.embedding.weight)\n",
    "a1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = model.embedding(torch.tensor(indexs).cuda()).sum(dim=0)\n",
    "a1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a1 != a2).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
