{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import argparse\n",
    "\n",
    "from model_bowloss import SentenceVAE\n",
    "from utils import to_var, idx2word, interpolate, AttributeDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'load_checkpoint': './bin/2019-Nov-29-07:07:02/E9.pytorch',\n",
    "    'num_samples': 10,\n",
    "    'max_sequence_length': 50,\n",
    "    'embedding_size': 300,\n",
    "    'rnn_type': 'gru',\n",
    "    'hidden_size': 256,\n",
    "    'word_dropout': 0,\n",
    "    'embedding_dropout': 0.5,\n",
    "    'latent_size': 16,\n",
    "    'num_layers': 1,\n",
    "    'bidirectional': False\n",
    "}\n",
    "args = AttributeDict(args)\n",
    "args.rnn_type = args.rnn_type.lower()\n",
    "assert args.rnn_type in ['rnn', 'lstm', 'gru']\n",
    "assert 0 <= args.word_dropout <= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(arr_like, cuda=True):\n",
    "    tensor = torch.Tensor(arr_like)\n",
    "    return tensor if not cuda else tensor.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/eccos/src/ptb.vocab.json', 'r') as file:\n",
    "        src_vocab = json.load(file)\n",
    "src_w2i, src_i2w = src_vocab['w2i'], src_vocab['i2w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/eccos/tgt/ptb.vocab.json', 'r') as file:\n",
    "        tgt_vocab = json.load(file)\n",
    "tgt_w2i, tgt_i2w = tgt_vocab['w2i'], tgt_vocab['i2w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5619, 12106)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(src_w2i), len(tgt_w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.obj['cond_embedding_size'] = 300\n",
    "# args.obj['cond_hidden_size'] = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptb import SOS_INDEX, EOS_INDEX, PAD_INDEX, UNK_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceVAE(\n",
    "    vocab_size=len(src_w2i),\n",
    "    out_vocab_size=len(tgt_w2i),\n",
    "    sos_idx=SOS_INDEX,\n",
    "    eos_idx=EOS_INDEX,\n",
    "    pad_idx=PAD_INDEX,\n",
    "    unk_idx=UNK_INDEX,\n",
    "    max_sequence_length=args.max_sequence_length,\n",
    "    embedding_size=args.embedding_size,\n",
    "    rnn_type=args.rnn_type,\n",
    "    hidden_size=args.hidden_size,\n",
    "    word_dropout=args.word_dropout,\n",
    "    embedding_dropout=args.embedding_dropout,\n",
    "    latent_size=args.latent_size,\n",
    "    num_layers=args.num_layers,\n",
    "    bidirectional=args.bidirectional,\n",
    "    \n",
    "    use_bow_loss=False,\n",
    "#     bow_hidden_size=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceVAE(\n",
       "  (embedding): Embedding(5619, 300)\n",
       "  (embedding_dropout): Dropout(p=0.5, inplace=False)\n",
       "  (decoder_embedding): Embedding(12106, 300)\n",
       "  (encoder_rnn): GRU(300, 256, batch_first=True)\n",
       "  (decoder_rnn): GRU(300, 256, batch_first=True)\n",
       "  (hidden2mean): Linear(in_features=256, out_features=16, bias=True)\n",
       "  (hidden2logv): Linear(in_features=256, out_features=16, bias=True)\n",
       "  (latent2hidden): Linear(in_features=16, out_features=256, bias=True)\n",
       "  (outputs2vocab): Linear(in_features=256, out_features=12106, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ./bin/2019-Nov-29-07:07:02/E9.pytorch\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(args.load_checkpoint):\n",
    "    raise FileNotFoundError(args.load_checkpoint)\n",
    "\n",
    "model.load_state_dict(torch.load(args.load_checkpoint))\n",
    "print(\"Model loaded from %s\"%(args.load_checkpoint))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceVAE(\n",
       "  (embedding): Embedding(5619, 300)\n",
       "  (embedding_dropout): Dropout(p=0.5, inplace=False)\n",
       "  (decoder_embedding): Embedding(12106, 300)\n",
       "  (encoder_rnn): GRU(300, 256, batch_first=True)\n",
       "  (decoder_rnn): GRU(300, 256, batch_first=True)\n",
       "  (hidden2mean): Linear(in_features=256, out_features=16, bias=True)\n",
       "  (hidden2logv): Linear(in_features=256, out_features=16, bias=True)\n",
       "  (latent2hidden): Linear(in_features=16, out_features=256, bias=True)\n",
       "  (outputs2vocab): Linear(in_features=256, out_features=12106, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample 指定 inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptb import PTB\n",
    "test_src_ptb = PTB(\n",
    "    data_dir='./data/eccos/src/',\n",
    "    split='test',\n",
    "    create_data=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ptb.PTB at 0x7f489e90b320>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_src_ptb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実際のデータ確認用\n",
    "def ids2text(id_list, ptb, sep=''):\n",
    "    return sep.join([ptb.i2w[f'{i}'] for i in id_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2ids(words, ptb):\n",
    "    assert type(words) == list\n",
    "    return [test_src_ptb.w2i.get(word, UNK_INDEX) for word in words]\n",
    "\n",
    "def words2sample(words, ptb):\n",
    "    id_list = [SOS_INDEX] + words2ids(words, ptb)\n",
    "    sample = {'input': id_list, 'length': len(id_list)}\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▼ Input length:4\n",
      "<sos> ランキング 化粧品 人気\n"
     ]
    }
   ],
   "source": [
    "# データをピックアップ, 確認\n",
    "# sample = words2sample('可愛い ファッション 春'.split(), test_src_ptb)\n",
    "sample = test_src_ptb.data['10']\n",
    "print(f'▼ Input length:{sample[\"length\"]}\\n{ids2text(sample[\"input\"], test_src_ptb, \" \")}')\n",
    "sample_input = to_tensor(sample['input']).view(1,-1).to(dtype=torch.int64)\n",
    "sample_length = to_tensor([sample['length']]).to(dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "■ 入力\n",
      "<sos> ランキング 化粧品 人気\n"
     ]
    }
   ],
   "source": [
    "# %pdb on\n",
    "# 潜在変数zの取得\n",
    "mean, logv, z = model.encode(sample_input, sample_length)\n",
    "samples, _ = model.inference(z=z)\n",
    "print('■ 入力')\n",
    "print(*idx2word(torch.Tensor(sample['input']).int().view(1, -1), i2w=src_i2w, pad_idx=PAD_INDEX), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "■ 一文サンプリング\n",
      "【<num>年版】のおすすめコスメ<num>選|domani\n"
     ]
    }
   ],
   "source": [
    "print('■ 一文サンプリング')\n",
    "print(*[s.replace('<eos>', '').replace(' ', '') for s in idx2word(samples, i2w=tgt_i2w, pad_idx=PAD_INDEX)], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "■ 入力\n",
      "<sos> ランキング 化粧品 人気\n",
      "■ 30件 サンプリング\n",
      "知ってる?知ってる?人気の「<unk>」がヤバい!\n",
      "美容効果が期待できる!「<unk>」のおすすめアイテム<num>選\n",
      "男ウケ抜群!「<unk>」の意外な用途になる方法\n",
      "口コミ評価試験!口コミで人気の「化粧水」まとめ\n",
      "人気モデルのモデルが誇るの?「<unk>」の魅力とは?\n",
      "【<num>年人気だった記事をおさらい♡】今年の夏は絶対買うべきはもう古い?\n",
      "「それどこ」がいいの?若い悩み別におすすめのアイテムを✓\n",
      "知ってる?知っておきたい知識<num>選\n",
      "【ランキング】のおすすめコスメ<num>選|domani\n",
      "人気の韓国ドラマのおすすめ美容室<num>選♪\n",
      "【<num>年最新版】人気ランキングランキング@cosme\n",
      "【<num>年版】のおすすめコスメ<num>選|domani\n",
      "人気の韓国ドラマ、しまむらの<num>年秋冬の美容法をおさらい!\n",
      "【ランキング】人気ランキングランキング@cosme\n",
      "【<num>年人気だった記事をおさらい♡】今年のトレンドは、``<unk>\"がキテる!\n",
      "【厳選】人気の香水ランキング@cosme\n",
      "<num>年福袋の中身ネタバレ\n",
      "メイク初心者<person>がこぞって使う「<unk>」のコスメが可愛すぎる件\n",
      "【<num>年人気だった記事をおさらい♡】今年のトレンドは、``<unk>\"がキテるらしい。\n",
      "【<num>円以下】人気のプチプラコスメまとめ\n",
      "コスパ最強!みんなお勧め「<unk>」が超優秀♡\n",
      "化粧水の化粧水はこれ!のびるてよかったスキンケア用品が優秀!\n",
      "【<num>年最新版】人気ランキングランキングランキング@cosme\n",
      "【<num>年人気だった記事をおさらい♡】今年のトレンドは、``<unk>\"がキテる!\n",
      "化粧品業界の化粧品ブランドまとめ\n",
      "【プチプラ】アトピーのいい香りでも使える!\n",
      "【<num>年】人気の育毛剤まとめ\n",
      "「<unk>」が人気の理由とは?\n",
      "【<num>】人気のプチプラコスメまとめ♡アットコスメ\n",
      "化粧品業界のパイオニアで、<unk>を<unk>に<unk>う!\n"
     ]
    }
   ],
   "source": [
    "# n回サンプリング\n",
    "args.num_samples = 30\n",
    "n_samples = [model.encode(sample_input, sample_length) for _ in range(args.num_samples)]\n",
    "z = torch.cat([z for mean, logv, z in n_samples])\n",
    "samples, _ = model.inference(z=z)\n",
    "print('■ 入力')\n",
    "print(*idx2word(torch.Tensor(sample['input']).int().view(1, -1), i2w=src_i2w, pad_idx=PAD_INDEX), sep='\\n')\n",
    "print(f'■ {args.num_samples}件 サンプリング')\n",
    "print(*[s.replace('<eos>', '').replace(' ', '') for s in idx2word(samples, i2w=tgt_i2w, pad_idx=PAD_INDEX)], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 潜在空間のプロット\n",
    "圧縮して分布を確認してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 描画用\n",
    "# https://github.com/lmcinnes/umap/blob/master/notebooks/UMAP%20usage%20and%20parameters.ipynb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(style='white', rc={'figure.figsize':(12,8)})\n",
    "def plot_scatter(u, title=''):\n",
    "    fig = plt.figure()\n",
    "    n_components = u.shape[1]\n",
    "    plot_kwargs = {'alpha': 0.5, 's':5}\n",
    "    if n_components == 1:\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.scatter(u[:,0], range(len(u)), **plot_kwargs)\n",
    "    if n_components == 2:\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.scatter(u[:,0], u[:,1], **plot_kwargs)\n",
    "    if n_components == 3:\n",
    "        ax = fig.add_subplot(111, projection='3d', **plot_kwargs)\n",
    "        ax.scatter(u[:,0], u[:,1], u[:,2])\n",
    "    plt.title(title, fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptb import PTB\n",
    "test_ptb = PTB(\n",
    "    data_dir='./data/eccos/tgt/',\n",
    "    split='test',\n",
    "    create_data=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_to_tensor(sample):\n",
    "    sample_input = to_tensor(sample['input']).view(1,-1).to(dtype=torch.int64)\n",
    "    sample_length = to_tensor([sample['length']]).to(dtype=torch.int64)\n",
    "    return sample_input, sample_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[0;32m~/user/work/src/Sentence-VAE/model_bowloss.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, input_sequence, length)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0minput_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mpacked_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/root/user/work/src/Sentence-VAE/model_bowloss.py\u001b[0m(101)\u001b[0;36mencode\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     99 \u001b[0;31m        \u001b[0minput_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    100 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 101 \u001b[0;31m        \u001b[0mpacked_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    102 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    103 \u001b[0;31m        \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# テストデータを潜在変数に変換\n",
    "with torch.no_grad():\n",
    "    encoded_samples = [model.encode(*sample_to_tensor(sample)) for i, sample in test_ptb.data.items()]\n",
    "    encoded_mean_list = [mean.tolist() for mean, std, z in encoded_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_mean_arr = np.array(encoded_mean_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_mean_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mean_u = umap.UMAP().fit_transform(encoded_mean_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_scatter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-24ec853022e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_scatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_u\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_scatter' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-99-24ec853022e7>\u001b[0m(1)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m----> 1 \u001b[0;31m\u001b[0mplot_scatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_u\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "plot_scatter(mean_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 分布の形の歪さは、umapの特性によるものなので、なんとも言えない\n",
    "- ただ、分布の中で偏りはある程度あるので、この偏りの箇所を確認したい\n",
    "- また、近しい箇所や遠い箇所で意味的な距離がありそうかを確かめたい"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
